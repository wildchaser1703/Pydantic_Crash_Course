1. Define a pydantic class(model) that represents the ideal schema of the data (Type validation and data validation)
    - This includes the expected fields, their types, and any validation constraints (eg: gt=0 for positive numbers)

2. Instantiate the model with raw input data (usually a dictionary or a JSON-like structure)
    -Pydantic will automatically validate the data and coerce it into the correct python types(if possible).
    - If the data doesn't meet the model requirements, then Pydantic raises a validation error

3. Pass the validated model object to functions or use it throughout your codebase.
    - This ensures that every part of your program works with clean, type-safe, andf logically valid data.

4. Use Field to set constarints on both the numerical as well as categorical data. It helps the developer to add metadata as well.

5. field_validator can be used in two modes, before and after. 
    - Before works when type coercion has not been performed. 
    - After is the default value. It works once type coercion is done. It is less likely to be prone to errors.  

6. For multiple checks use model_validator by combining multiple field together. 

7. Computed fields can be used when you want to compute something based on the pre-existing values.

8. Nested models can be used where there is some data hierarchy:
    - lengthy data fields can be organised better (address, vitals, etc.)
    - reusability : can be used in multiple models (patient, mediacl records, etc.)
    - readability : it is easier for developers and API consumers to understand
    - validation : nested models are automatically validated
    